{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络简介\n",
    "这次的可成主要是介绍神经网络的基础知识，再介绍神经网络的同时，我们也将结合神经网络对以前学过的梯度下降，线性回归和逻辑斯蒂回归知识进行扩展。本章主要需要学习以下几点：\n",
    "+ 训练简单的神经网络\n",
    "+ 反向传播算法\n",
    "+ 梯度误差计算\n",
    "+ 简单神经网络架构\n",
    "+ 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 感知机\n",
    "感知器（英语：Perceptron）是弗兰克·罗森布拉特在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网路。它可以被视为一种最简单形式的前馈神经网路，是一种二元线性分类器。感知机是一种二类分类的线性分类模型，输入为实例的特征向量，输出为实例的类别，正类取1，负类取-1。感知机是一种判别模型，其目标是求得一个能够将数据集中的正实例点和负实例点完全分开的分离超平面。如果数据不是线性可分的，则最后无法获得分离超平面。\n",
    "\n",
    "感知机是生物神经细胞的简单抽象。神经细胞结构大致可分为：树突、突触、细胞体及轴突。单个神经细胞可被视为一种只有两种状态的机器——激动时为‘是’，而未激动时为‘否’。神经细胞的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某个阈值时，细胞体就会激动，产生电脉冲。电脉冲沿着轴突并通过突触传递到其它神经元。为了模拟神经细胞行为，与之对应的感知机基础概念被提出，如权量（突触）、偏置（阈值）及激活函数（细胞体）。\n",
    "\n",
    "在人工神经网络领域中，感知机也被指为单层的人工神经网络，以区别于较复杂的多层感知机（Multilayer Perceptron）。作为一种线性分类器，（单层）感知机可说是最简单的前向人工神经网络形式。尽管结构简单，感知机能够学习并解决相当复杂的问题。感知机主要的本质缺陷是它不能处理线性不可分问题。\n",
    "\n",
    "**线性可分**：线性可分就是说可以用一个线性函数把两类样本分开，比如二维空间中的直线、三维空间中的平面以及高维空间中的线性函数。\n",
    "\n",
    "感知器是神经⽹络的构建模块。它通常具有多个连接的输⼊，并根据传⼊连接（突触）的加权和计算输出，也称为激活函数。下图是一个感知机模型实例，对于作用于与输入$X=(x_1,x_2,\\cdots,x_n)$的权重$W=(w_1,w_2,\\cdots,w_n)$其输出$Z$经过激活函数$O$,那么其结构如下图所示：\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "其中输出满足:\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "\n",
    "用简单的向量表示如下：\n",
    "\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "感知机的训练要素：\n",
    "+ 训练样本线性可分\n",
    "+ 学习率足够小\n",
    "利用梯度下降训练的成功要素:\n",
    "+ SME收敛到样本假设\n",
    "+ 学习率足够小\n",
    "+ 即使训练样本有噪声\n",
    "\n",
    "下⾯是如何使⽤感知器来学习⼀个简单问题（即“或”⻔）的⽰例。或⻔是⽤于基本机器学习的简单⽰例。与异或⻔相⽐，\n",
    "或⻔更容易学习。与 XOR ⻔类似，OR ⻔有 4 个实例，这些实例具有两个特征，并且输出 (OR) 为 0 或 1。该模型的⽬标\n",
    "是最小化或门的最⼩平⽅误差收敛到假设，即给定输⼊预测表⽰或⻔的输出。\n",
    "\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "那么，感知机的学习算法可以分为以下几步：\n",
    "\n",
    "![Alt text](image-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  for input [1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Perceptron(object):\n",
    "    def __init__(self, no_of_inputs, threshold, learning_rate):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0\n",
    "        return activation\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                #print(prediction, label)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction) #bias\n",
    "\n",
    "    # set the dataset inputs\n",
    "# AND gate\n",
    "training_inputs = []\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "# set the dataset class labels\n",
    "labels = np.array([1, 0, 0, 0])# AND\n",
    "#labels = np.array([1, 0, 0, 1]) #XOR\n",
    "#labels = np.array([1, 1, 1, 0]) # OR\n",
    "no_of_inputs = 2\n",
    "threshold=100\n",
    "learning_rate=0.01\n",
    "# set the class and train\n",
    "perceptron = Perceptron(no_of_inputs, threshold, learning_rate)\n",
    "perceptron.train(training_inputs, labels)\n",
    "# now test trained percepton\n",
    "inputs = np.array([1, 1])\n",
    "output = perceptron.predict(inputs)\n",
    "print(output, ' for input [1, 1]' )\n",
    "inputs = np.array([0, 1])\n",
    "output = perceptron.predict(inputs)\n",
    "print(output, ' for input [0, 1]' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 多层感知机\n",
    "\n",
    "###  1.3.1 反向传播算法\n",
    "\n",
    "### 1.3.2 前向传播\n",
    "\n",
    "### 1.3.3 损失函数\n",
    "\n",
    "### 1.3.4 前传\n",
    "\n",
    "### 1.3.5 反传\n",
    "\n",
    "### 1.3.6 反向传播\n",
    "\n",
    "### 1.3.7 网络测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 前馈神经网络\n",
    "\n",
    "### 1.4.1 前馈神经网络1\n",
    "\n",
    "### 1.4.2 前馈神经网络2\n",
    "\n",
    "### 1.4.3 网络训练和学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Sklearn库的神经网络\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "### 隐藏层设计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
